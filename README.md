# POSE-ESTIMINATION-OF-GYM-WORKOUT-USING-YOLOV7

# Aim:
Human Pose Estimation is a computer vision-based technology that identifies and classifies specific points on the human body.These points represent our limbs and joints to calculate the angle of flexion, and estimate, well, human pose.
# About:
Position estimation is a computer vision technique that predicts and tracks not only the location of a person or object but the joints specifically. Remarkable progress has been made in posture estimation
so far, but still recognizing human activities in real-life settings remains unsettled. This task becomes even more challenging when approaching this not from standalone cameras in offline mode, but from 
smartphones in real-time. This happens because real-time execution significantly raises input data through put and computations needed, while mobile devices are still limited in available computational
resources.
# Features
```
-Real-Time Pose Estimation
-Dynamic Movement Tracking
-Enhanced Accuracy and Speed
-Error Detection and Correction
-Multi-Activity Compatibility
-User-Centric Design
```
# Requirements:
```
@ Software Requirements:

Python 3.8+: Main programming language for development.
YOLOv7 Framework: For pose estimation.
PyTorch: Deep learning framework for model implementation.
OpenCV: For video and image processing.
NumPy: For efficient numerical computations.
Matplotlib/Seaborn: For visualizing pose data and analytics.
Anaconda: Development environment with Jupyter Notebook.

@ Hardware Requirements

CPU: Intel i5 or better (recommended: i7 or Ryzen equivalent).
GPU: NVIDIA GPU with CUDA support (e.g., GTX 1660 or higher) for model training and testing.
RAM: Minimum 8 GB (recommended: 16 GB for smooth processing).
Storage: 500 GB or more (SSD preferred for faster data access).
Camera: High-resolution camera for accurate pose detection during testing.
```
# System Architecture:
![Picture1](https://github.com/user-attachments/assets/c7188f51-3a1a-4512-836e-0698d0260bf1)
# Output:
### ERROR RECTIFICATION - IN ANACONDA CONVERTER THE CONDA BASE INTO YOLO USING THE BELOW IMAGE  
![Screenshot 2024-11-29 211125](https://github.com/user-attachments/assets/618e7c4e-0756-4eb7-8e1a-1d4e7b191f5d)


### AFTER THAT,  THE PROGRAM WILL RUN THEN IT WILL LOOK LIKE, GIVEN OUTPUT 
![Screenshot 2024-11-22 114909](https://github.com/user-attachments/assets/1967bda1-4c77-48d7-86b0-943b424732a1)

### ERROR - THE SHOULDERS SHOULD BE IN STRAIGHT CORRECT POSITION AND SHOULD BE ALIGN IN 35 DEGREE 
![Screenshot 2024-11-22 115109](https://github.com/user-attachments/assets/3b5a6d6c-c3c7-44b6-a0d7-8e6df4eb860e)


### BY SHAKING SHOLDERS AND HANDS GET THE OUTPUT
![Screenshot 2024-11-22 115047](https://github.com/user-attachments/assets/5b766e49-c4f5-487e-b029-c194ba3159b5)


### THE FINAL OUTPUT AND REP COUNT IS NOTED IN THE IMAGE 
![Screenshot 2024-11-22 115143](https://github.com/user-attachments/assets/d158d250-0d4d-4694-9d47-ea417fb5a566)


# Results of the "POSE-ESTIMINATION-OF-GYM-WORKOUT-USING-YOLOV7" Project:

In conclusion, gym pose estimation technology has emerged as a valuable tool in the fitness industry, offering numerous benefits for both individuals and fitness professionals. This technology utilizes computer vision algorithms and deep learning techniques to accurately track and analyze human movement during exercise routines. One key advantage of gym pose estimation is its ability to provide real-time feedback and guidance to users. By tracking the body's position and alignment, it can identify errors in form or technique, helping individuals to correct their posture and reduce the risk of injury. This instant feedback can enhance the effectiveness of workouts and contribute to better overall results. Moreover, gym pose estimation allows for precise tracking of various exercises and movements. It can recognize and differentiate between different poses, such as squats, lunges, push-ups, or yoga asanas. This versatility makes it a useful tool for a wide range of fitness activities and training programs.
![image](https://github.com/user-attachments/assets/612fe736-6785-4523-a149-ecc387e0e34d)



# Articles published / References:
-I.	[1 Liu, Y., Xu, Y., Li, S.: 2-D human pose estimation from images based on deep learning: a review. In: 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC), Xi’an, pp. 462–465 (2018)

-II.	Tang, Z., Gu, R., Hwang, J.: Joint multi-view people tracking and pose estimation for 3D scene reconstruction. In: 2018 IEEE International Conference on Multimedia and Expo (ICME), San Diego, CA, pp. 1–6 (2018)

-III.	Takahashi, K., Mikami, D., Isogawa, M., Kimata, H.: Human pose as calibration pattern: 3D human pose estimation with multiple unsynchronized and uncalibrated cameras. In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Salt Lake City, UT, USA, pp. 1856–18567 (2018)

-IV.	Fang, H., Xie, S., Tai, Y., Lu, C.: RMPE: regional multi-person pose estimation. In: 2017 IEEE International Conference on Computer Vision (ICCV), Venice, pp. 2353–2362 (2017)

-V.	[5]	R. T. S. A. a. R. M. R. G. Sharma, "A novel real-time face detection system using modified affine transformation and Haar cascades," Recent Findings in Intelligent Computing Techniques. Springer, Singapore, no. 193-204, 2019.

-VI.	[6]	S. R. Y. W. X. C. a. J. S. D. Chen, "Joint cascade face detection and alignment," Proc. ECCV, 2014.

-VII.	[7]	D. R. X. Zhu, "Face detection, pose estimation, and landmark localization in the wild," IEEE Conference on Computer Vision and Pattern Recognition, pp. 2879-2886, 2012 



















