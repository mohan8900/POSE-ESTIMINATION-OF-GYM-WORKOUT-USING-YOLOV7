# POSE-ESTIMINATION-OF-GYM-WORKOUT-USING-YOLOV7

# Aim:
Human Pose Estimation is a computer vision-based technology that identifies and classifies specific points on the human body.These points represent our limbs and joints to calculate the angle of flexion, and estimate, well, human pose. While it sounds awkward, knowing the right angle of a joint in a specific exercise is the basis of work for physiotherapists, fitness trainers, and artists. Implementing such capabilities for a machine results in surprisingly useful applications in different fields.
# About:
Position estimation is a computer vision technique that predicts and tracks not only the location of a person or object but the joints specifically. Remarkable progress has been made in posture estimation
so far, but still recognizing human activities in real-life settings remains unsettled. This task becomes even more challenging when approaching this not from standalone cameras in offline mode, but from 
smartphones in real-time. This happens because real-time execution significantly raises input data through put and computations needed, while mobile devices are still limited in available computational
resources.
# Features
```
-Real-Time Pose Estimation
-Dynamic Movement Tracking
-Enhanced Accuracy and Speed
-Error Detection and Correction
-Multi-Activity Compatibility
-User-Centric Design
```
# Requirements:
```
@ Software Requirements:

Python 3.8+: Main programming language for development.
YOLOv7 Framework: For pose estimation.
PyTorch: Deep learning framework for model implementation.
OpenCV: For video and image processing.
NumPy: For efficient numerical computations.
Matplotlib/Seaborn: For visualizing pose data and analytics.
Anaconda: Development environment with Jupyter Notebook.

@ Hardware Requirements

CPU: Intel i5 or better (recommended: i7 or Ryzen equivalent).
GPU: NVIDIA GPU with CUDA support (e.g., GTX 1660 or higher) for model training and testing.
RAM: Minimum 8 GB (recommended: 16 GB for smooth processing).
Storage: 500 GB or more (SSD preferred for faster data access).
Camera: High-resolution camera for accurate pose detection during testing.
```
# System Architecture:
https://github.com/mohan8900/POSE-ESTIMINATION-OF-GYM-WORKOUT-USING-YOLOV7/blob/main/Picture1.png
# Output:
### After browsing for our website, the following page will be shown first. 
![image](https://github.com/user-attachments/assets/7c288e5f-1784-42c4-ade8-ecd702717239)

### Click the browse file buttom to upload the pdf documents
![image](https://github.com/user-attachments/assets/a2d48321-6658-4746-9e49-3006689d5045)

### After uploading the pdf doc’s click on summit & process button
![image](https://github.com/user-attachments/assets/3a7236a4-62f3-41ff-ade4-a4fc99911cae)

### Then ask the question which is related to the uploaded pdf’s and it will give you the content of the related query asked.
![image](https://github.com/user-attachments/assets/580c1710-2d54-4f89-9caa-6c6f1a425ac1)

### Additionly we give that you can print the content,record a screencast,setting(change background mode & change the font ).  
![image](https://github.com/user-attachments/assets/40020dc2-d9ca-47af-988b-4ed81fc96b0d)

# Results of the "Chat with PDF using Gemini" Project:

PDF Upload & Processing:
Result: Text extracted from PDFs, split into chunks, and embeddings created/stored in FAISS.
Success Message: "Processing completed!"

User Question Submission:
Result: Relevant text chunks are retrieved from the FAISS index based on the user's question.

Answer Generation:
Result: Google Generative AI generates an accurate answer from the PDF content.
Example: User asks, "What are the climate change factors?"
Generated Answer: "Temperature changes, altered rainfall, and CO2 levels."

Edge Cases:
No PDFs: Error: "Please upload a PDF."
No Answer: Response: "Answer is not available in the context.

# Articles published / References:
[1] Asbjørn Følstad and Marita Skjuve. 2019. Chatbots for customer service: user experience and motivation. In Proceedings of the 1st International Conference on Conversational User Interfaces (CUI '19). Association for Computing Machinery, New York, NY, USA, Article 1, 1–9. https://doi.org/10.1145/3342775.3342784
[2] Su, Hongjin, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen Yih, Noah A. Smith, Luke Zettlemoyer, and Tao Yu. "One Embedder, Any Task: Instruction-Finetuned Text Embeddings." ArXiv, (2022). /abs/2212.09741. N W Marti et al 2020 J. Phys.: Conf. Ser. 1516 012022
[3] Kim, S., Rawat, A. S., Zaheer, M., Jayasumana, S., Sadhanala, V., Jitkrittum, W., Menon, A. K., Fergus, R., & Kumar, S. (2023). EmbedDistill: A Geometric Knowledge Distillation for Information Retrieval. ArXiv. /abs/2301.12005 
[4] Dao, Mai Thi Hong. "International Journal of Management and Organizational Research." (2023)

[5] Jahan, Md Saroar, et al. "A Comprehensive Study on NLP Data Augmentation for Hate Speech Detection: Legacy Methods, BERT, and LLMs." arXiv preprint arXiv:2404.00303 (2024).
[6] Malode, Vishal Manjunatha. Benchmarking public large language model. Diss. Technische Hochschule Ingolstadt, 2024.
[7] L. Padoan, M. Cesetti, L. Brunello, M. Antonelli, B. Zamengo and F. Silvestri, "Mobility ChatBot: supporting decision making in mobility data with chatbots," 2024 25th IEEE International Conference on Mobile Data Management (MDM), Brussels, Belgium, 2024, pp. 295-300, doi: 10.1109/MDM61037.2024.00061. keywords: {Structured Query Language;Large language models;Decision making;Natural languages;Data visualization;Transportation;Writing;Mobility data;Large Language Models;decision making;agents},


















